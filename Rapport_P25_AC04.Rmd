---
title: "Bilan"
author: "MAROS Enzo, PRUVOST LAMY Andr√©a, RANDRETH Aaron, ZHANG Anxian"
date: "`r Sys.Date()`"
output:
  html_document:
   toc: true
   toc-location: left
   cap-location: margin
   code-fold: false
   highlight-style: github
   code-copy: true
   html-math-method: katex
   number-sections: true
   code-line-numbers: false
   include-after-body:
        text: |
          <script>
          const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
          for (var i=0; i<noterefs.length; i++) {
            const ref = noterefs[i];
            ref.onclick = function(){ref._tippy.show();return false;};
          }
          </script>
   embed-resources: true
   self-contained-math: true
---

# TP Projet AC04

## Introduction

Ce document pr√©sente le code, les r√©sultats et les conclusions du projet de
r√©gression lin√©aire r√©alis√© dans le cadre de l'UV AC04, *M√©thodes Statistiques
pour l'Ing√©nieur*.

Les membres de l'√©quipe sont pr√©sent√©s dans le tableau ci-dessous, avec le
pourcentage de contribution de chacun au projet (Question 0). La collaboration a
√©t√© √©quitable, les sessions de travail ont √©t√© organis√©es ensemble, et les
r√©flexions ont √©t√© partag√©es en tous temps. Chaque membre a ainsi contribu√©
de mani√®re parfaitement √©gale √† la r√©alisation de ce projet.

| Nom et pr√©nom                | Contribution |
|------------------------------|--------------|
| MAROS Enzo                   | 25%          |
| PRUVOST LAMY Andrea          | 25%          |
| RANDRETH Aaron               | 25%          |
| ZHANG Anxian                 | 25%          |

*L'ensemble des formules math√©matiques dans ce document est r√©dig√© en LaTeX.*
*L'ensemble des formules math√©matiques dans le code R est g√©n√©r√© par un outil*
*de conversion de LaTeX vers Unicode, quand possible.*

*Certaines portions de code ont √©t√© retir√©es du fichier HTML g√©n√©r√©, afin de*
*mettre en avant le r√©sultat (tableau, graphique) quand le proc√©d√© utilis√©*
*n'apporte que peu d'informations. Tous ces morceaux de code sont toutefois*
*disponibles dans le fichier .Rmd, en clair, et sont document√©s.*

*Pour la bonne execution du fichier .Rmd :  `bodyfat.dat`, `car.csv`, `hapiness_csv.csv`, et `utils.R` doivent √™tre pr√©sent dans le m√™me r√©pertoire.*

## 2. Donn√©es simul√©es

Pour comprendre la notion de r√©gression lin√©aire, nous commen√ßons par simuler un jeu de donn√©es simple, que nous √©tudierons ensuite. Les param√®tres du mod√®le sont choisis al√©atoirement au d√©but, puis sont consid√©r√©s comme inconnus pour la suite de l'analyse.

Soient $(x_1, \dots, x_n)$ les valeurs r√©elles de la **variable explicative**, et $(Y_1, \dots, Y_n)$ un √©chantillon de la **variable √† expliquer** $Y$, de r√©alisations $(y_i)_i$, avec $i \in \{1, \dots, n\}$.
On pose le mod√®le de r√©gression lin√©aire suivant :

$$ \forall i \in \{1, \dots, n\},\ Y_i = a + b x_i + \varepsilon_i $$

On consid√®re que les erreurs $(\varepsilon_i)_i$ suivent une m√™me loi normale centr√©e
de variance $\sigma^2$, autrement dit :

$$
  (\varepsilon_1, \dots, \varepsilon_n)
  \overset{\mathrm{iid}}{\sim}
  \mathcal{N}(0, \sigma^2)
$$

Nos trois param√®tres inconnus sont donc $a$, $b$ et $\sigma^2$.

```{r, echo=FALSE}
rm(list = ls())
# Figer le caract√®re al√©atoire (nombre choisi arbitrairement)
set.seed(92)
```

```{r}
a0 <- round(runif(1, 3, 15), 2)
b0 <- round(runif(1, 1, 5), 2)
s0 <- round(runif(1, 1, 3), 2)

# Afficher les param√®tres du mod√®le
c("a" = a0, "b" = b0, "œÉ¬≤" = s0)
```
```{r, echo=FALSE}
# Rendre les valeurs constantes
lockBinding("a0", globalenv())
lockBinding("b0", globalenv())
lockBinding("s0", globalenv())
```

### Question 1A
On commence par simuler un jeu de donn√©es de taille $n$, en g√©n√©rant les
valeurs de la variable explicative $x_i$.
Pour s'assurer que les valeurs soient bien r√©parties et donc que la r√©gression
lin√©aire soit pertinente, on utilise une loi uniforme sur l'intervalle $[0, 5]$.

```{r, echo=FALSE}
min_n <- 200
lockBinding("min_n", globalenv())
```

Le jeu de donn√©es devant √™tre plus grand que `r min_n` √©l√©ments (*d√©fini par
`min_n` dans le code)*, nous posons $n = 300$.
Par la suite, il pourra √™tre n√©cessaire de g√©n√©rer d'autres jeux de donn√©es,
de tailles diff√©rentes, pour √©tudier des propri√©t√©s de convergence des
estimateurs par exemple.
La fonction `gen_x` est cr√©√©e pour faciliter et uniformiser cette t√¢che.

```{r}
#' G√©n√®re n r√©alisations de la variable explicative.
#' @param n Nombre de r√©alisations √† g√©n√©rer.
#' @return Un vecteur de taille n contenant les r√©alisations.
gen_x <- function(n) {
  stopifnot(n >= min_n)
  runif(n, 0, 5)
}

x <- gen_x(300)
```

### Question 1B
On cherche maintenant √† g√©n√©rer les valeurs de la variable √† expliquer $Y_i$.
On ne connait pas sa loi pr√©cise, mais on peut la d√©duire √† partir de celle des
erreurs $\varepsilon_i$ :

$$
\begin{align*}
\varepsilon_i &\sim \mathcal{N}(0, \sigma^2) \\
\iff \varepsilon_i + a + b x_i &\sim \mathcal{N}(a + b x_i, \sigma^2) \\
\iff Y_i &\sim \mathcal{N}(a + b x_i, \sigma^2)
\end{align*}
$$

Cette formule est vraie pour tout $i \in \{1, \dots, n\}$ car les
$(\varepsilon_i)_i$ sont ind√©pendantes et identiquement distribu√©es (iid), et
que $(a + b x_i) \in \mathbb{R}$.

Au m√™me titre que pour la variable explicative, on cr√©e une fonction `gen_y`
pour faciliter et uniformiser la g√©n√©ration de la variable √† expliquer.

```{r}
#' G√©n√®re les r√©alisations de la variable √† expliquer.
#' @param x_ R√©alisations de la variable explicative.
#' @return Un vecteur de m√™me taille que x_ contenant les r√©alisations.
gen_y <- function(x_) {
  stopifnot(length(x_) >= min_n)
  n <- length(x_)

  # R utilise l'√©cart-type pour les lois normales
  sd0 <- sqrt(s0)
  rnorm(n, mean = a0 + b0 * x_, sd = sd0)
}

y <- gen_y(x)
```

Une autre mani√®re de g√©n√©rer les valeurs de la variable √† expliquer aurait √©t√©
de g√©n√©rer les erreurs $(\varepsilon_i)_i$, puis d'appliquer la formule
lin√©aire.
La version actuellement utilis√©e est plus optimis√©e, en temps comme en m√©moire,
et est plus concise.

Nos couples $(x_i, y_i)$ sont maintenant g√©n√©r√©s, en voici un √©chantillon :
```{r echo=FALSE}
head(data.frame("x·µ¢" = x, "y·µ¢" = y), 5)
```

### Question 2
Pour visualiser les donn√©es, on trace un nuage de points, en ajoutant la droite
de r√©gression lin√©aire r√©elle.
Le graphique nous montre que les donn√©es sont bien r√©parties autour de cette
droite, √©quitablement au-dessus et au-dessous, ce qui est en coh√©rence avec le
mod√®le d√©fini plus haut, et avec la sym√©trie de la loi normale des erreurs.

```{r echo=FALSE}
m <- 20
```

Pour mieux visualiser les erreurs, on propose un second graphique sur un
√©chantillon de `r m` points des donn√©es g√©n√©r√©es, o√π l'on trace les segments
reliant les points √† la droite de r√©gression r√©elle.
La taille des segments correspond √† l'erreur.

```{r echo=FALSE}
par(mfrow = c(1, 2))

# Afficher un nuage de points
plot(x, y,
  pch = 20,
  xlim = c(0, 5),
  ylim = c(min(y), max(y)),
  xlab = "Variable explicative (x·µ¢)",
  ylab = "Variable √† expliquer (y·µ¢)",
  main = "Donn√©es simul√©es et\n r√©gression lin√©aire"
)
abline(a0, b0, col = "red", lwd = 2)

echantillon_x <- head(x, m)
echantillon_y <- head(y, m)
plot(echantillon_x, echantillon_y,
  pch = 20,
  xlim = c(0, 5),
  ylim = c(min(y), max(y)),
  xlab = "Variable explicative (x·µ¢)",
  ylab = "Variable √† expliquer (y·µ¢)",
  main = "Erreurs par rapport\n √† la droite de r√©gression"
)
abline(a0, b0, col = "red", lwd = 2)
segments(echantillon_x, echantillon_y, echantillon_x, a0 + b0 * echantillon_x)
```

### Question 3
On peut maintenant estimer les param√®tres du mod√®le, en les consid√©rant inconnus
et en ne se basant que sur les donn√©es simul√©es. On utilise la m√©thode du maximum
de vraisemblance pour estimer les param√®tres, en les prenant sans biais.

Pour √©viter toute confusion, les vecteurs utilis√©s dans les fonctions sont
nomm√©s `x_` et `y_`. Chaque estimateur :

- V√©rifie la validit√© des vecteurs transmis,
- Calcule les variables interm√©diaires n√©cessaires,
- Retourne l'estimation du param√®tre demand√©.

```{r}
#' V√©rifie que les vecteurs x_ et y_ transmis aux estimateurs sont valides.
#' @param x_ Vecteur de la variable explicative.
#' @param y_ Vecteur de la variable √† expliquer.
#' @return Rien, mais g√©n√®re une erreur si les vecteurs ne sont pas valides.
assert_valid <- function(x_, y_) {
  stopifnot(length(x_) == length(y_))
  stopifnot(length(x_) > 2)
}

#' Estime le param√®tre b du mod√®le de r√©gression lin√©aire.
#' @param x_ Vecteur de la variable explicative.
#' @param y_ Vecteur de la variable √† expliquer.
#' @return Le param√®tre b estim√©.
b_estim <- function(x_, y_) {
  assert_valid(x_, y_)

  n <- length(x_)
  S_xY <- sum(x_ * y_) / n - mean(x_) * mean(y_)
  s_x2 <- sum(x_^2) / n - mean(x_)^2

  S_xY / s_x2
}

#' Estime le param√®tre a du mod√®le de r√©gression lin√©aire.
#' @param x_ Vecteur de la variable explicative.
#' @param y_ Vecteur de la variable √† expliquer.
#' @return Le param√®tre a estim√©.
a_estim <- function(x_, y_) {
  assert_valid(x_, y_)

  b_hat <- b_estim(x_, y_)
  y_bar <- mean(y_)
  x_bar <- mean(x_)

  y_bar - b_hat * x_bar
}

#' Estime le param√®tre œÉ¬≤ des erreurs.
#' @param x_ Vecteur de la variable explicative.
#' @param y_ Vecteur de la variable √† expliquer.
#' @return Le param√®tre œÉ¬≤ estim√©.
sigma_estim <- function(x_, y_) {
  assert_valid(x_, y_)

  n <- length(x_)
  a_hat <- a_estim(x_, y_)
  b_hat <- b_estim(x_, y_)

  sum((y_ - a_hat - b_hat * x_)^2) / (n - 2)
}
```

### Question 4
Maintenant que nos fonctions sont d√©finies, nous pouvons les utiliser avec
les donn√©es existantes pour en calculer les estimations de $a$, $b$ et $\sigma^2$
que l'on nommera respectivement $\hat{a}$, $\hat{b}$ et $\hat{\sigma}^2$.
```{r}
a_hat <- a_estim(x, y)
b_hat <- b_estim(x, y)
s_hat <- sigma_estim(x, y)

# Afficher les param√®tres estim√©s
c("^a" = a_hat, "^b" = b_hat, "^œÉ¬≤" = s_hat)
```

### Question 5
Les estimations calcul√©es semblent relativement proches des param√®tres g√©n√©r√©s
en Question 1. Pour v√©rifier visuellement cette hypoth√®se, nous reprenons le
premier graphique de la Question 2, en y ajoutant la droite de r√©gression
lin√©aire calcul√©e par les estimateurs (en bleu).

```{r, echo=FALSE}
plot(x, y,
  pch = 20,
  xlab = "Variable explicative (x·µ¢)",
  ylab = "Variable √† expliquer (y·µ¢)",
  main = "Droites de r√©gression lin√©aires r√©elle et estim√©e"
)

abline(a = a0, b = b0, col = "red", lwd = 2)
abline(a_hat, b_hat, col = "blue", lwd = 2)
legend("topleft",
  lwd = "2",
  legend = c("R√©elle", "Estim√©e"),
  col = c("red", "blue")
)
```

### Question 6
On calcule maintenant les r√©sidus, repr√©sent√©s par la diff√©rence entre les
valeurs de $Y_i$ et les valeurs estim√©es par le mod√®le de r√©gression lin√©aire.

```{r}
y_hat <- a_hat + b_hat * x
e_hat <- y - y_hat
```

Un √©chantillon des 5 premiers r√©sidus calcul√©s ressemble √† ceci :
```{r, echo=FALSE}
# Afficher les premiers r√©sidus
head(data.frame("y·µ¢" = y, "≈∑·µ¢" = y_hat, "√™·µ¢" = e_hat), 5)
```

Pour v√©rifier la validit√© des r√©sidus, on peut calculer la moyenne empirique et
la variance empirique corrig√©e, deux estimateurs de la moyenne et de la variance
des r√©sidus. En effet, d'apr√®s l'√©nonc√© du mod√®le, on a :

$$
  (\varepsilon_1, \dots, \varepsilon_n)
  \overset{\mathrm{iid}}{\sim}
  \mathcal{N}(0, \sigma ^2)
$$

On note les deux estimateurs $\hat{\mu}$ et $\hat{\sigma}^2$ respectivement la
moyenne et la variance des r√©sidus.

```{r}
c(
  "^Œº" = round(mean(e_hat), 5),
  "^œÉ¬≤" = round(var(e_hat), 5)
)
```

On remarque ici que la moyenne des r√©sidus est proche de $0$, et que la variance
est proche du param√®tre `s0` utilis√© pour g√©n√©rer les donn√©es ($`r s0`$).

### Question 7

Un autre moyen de v√©rifier la coh√©rence de nos r√©sultats est de s'assurer que
le point de coordonn√©es $(\bar{x}, \bar{y})$ est sur la droite de r√©gression
estim√©e.

```{r}
x_bar <- mean(x)
y_bar <- mean(y)

y_droite <- a_hat + b_hat * x_bar

# Afficher
c(
  "xÃÑ" = x_bar,
  "yÃÑ" = y_bar,
  "≈∑" = y_droite
)
```

Visuellement, ce point peut √™tre repr√©sent√© en rouge sur le graphique suivant,
ne comprenant que la droite de r√©gression estim√©e.

Afin de mieux visualiser cette appartenance, il est possible de reprendre le
graphique g√©n√©r√© √† la question 2, avec cette fois-ci la droite de r√©gression
lin√©aire estim√©e, ainsi qu'un nouveau point en rouge repr√©sentant
$(\bar{x}, \bar{y})$.

```{r, echo=FALSE}
plot(x, y,
  pch = 20,
  xlab = "Variable explicative (x·µ¢)",
  ylab = "Variable √† expliquer (Y·µ¢)",
  main = "Appartenance du point (¬Øx, ¬Øy) √† la\ndroite de r√©gression lin√©aire",
  col = "grey"
)

abline(a_hat, b_hat, col = "black", lwd = 2)
points(x_bar, y_bar, col = "red", pch = 20)
legend("topleft",
  legend = c("Courbe des moindres carre", "Centre de gravite", "Jeu de donn√©es"),
  # les couleurs doivent coincider avec celles trac√©es plus haut
  col = c("black", "red", "grey"),
  # resp. l√©gende avec des points et ligne
  pch = c(NA, 20, 20),
  lty = c(1, NA, NA),
  lwd = c(2, NA, NA)
)
```


### Question 8

En utilisant la pleine puissance de R, on peut v√©rifier toutes les donn√©es
pr√©c√©demment calcul√©es en une seule ligne :

```{r}
reg <- lm(y ~ x)
summary(reg)
```

De cette commande on peut extraire les param√®tres estim√©s
$\hat{a} = `r reg$coefficients["(Intercept)"]`$ et
$\hat{b} = `r reg$coefficients["x"]`$.

On peut √©galement v√©rifier la coh√©rence des r√©sidus, en regardant leur moyenne
et leur variance. La fonction calcule pour nous l'ensemble des r√©sidus,
accessibles via `reg$residuals`.

```{r}
c(
  "^Œº" = round(mean(reg$residuals), 5),
  "^œÉ¬≤" = round(var(reg$residuals), 5)
)
```

Une derni√®re approche de v√©rification serait de comparer les quartiles et
extrema calcul√©s par la fonction `lm` avec ceux de nos r√©sidus :
```{r}
# Matrice de comparaison
m_comp <- matrix(nrow = 2, ncol = 5)

# Donn√©es
m_comp[1, ] <- c(
  min(e_hat),
  quantile(e_hat, 0.25),
  median(e_hat),
  quantile(e_hat, 0.75),
  max(e_hat)
)
m_comp[2, ] <- c(
  min(reg$residuals),
  quantile(reg$residuals, 0.25),
  median(reg$residuals),
  quantile(reg$residuals, 0.75),
  max(reg$residuals)
)

# Noms des lignes et colonnes
colnames(m_comp) <- c("Min", "Q1", "Median", "Q3", "Max")
rownames(m_comp) <- c("e_hat", "reg$residuals")

m_comp
```

Nous en concluons ainsi que nos pr√©c√©dentes estimations sont correctement
calcul√©es, et proc√©dons √† la suite du projet.


### Question 9

#### Courbe des moyennes des erreurs

Nous cherchons √† √©tudier le comportement asymptotique des estimateurs de $a$ et du $b$. Une premi√®re approche est de calculer la moyenne d'un √©chantillon de 100 estimations, chaque estimation sur des jeux de donn√©es diff√©rents, et pour diff√©rentes tailles de jeux de donn√©es.

Pour rapporter les deux convergences des estimateurs sur un m√™me graphique, on calcule plut√¥t la moyenne des erreurs des estimations, √©tant donn√© que l'on conna√Æt les valeurs r√©elles de $a$ et de $b$. Si nos estimateurs sont bons, l'erreur devrait tendre vers $0$ pour $n$ grand.

On commence par g√©n√©rer les fonctions qui vont nous servir pour la g√©n√©ration des donn√©es :

```{r eval=TRUE}
#' Calcule la diff√©rence entre une estimation et sa valeur r√©elle.
#' @param size Taille des √©chantillons √† g√©n√©rer.
#' @param estimator Fonction calculant l'estimation √† partir des donn√©es.
#' @param real Valeur r√©elle de la variable estim√©e.
#' @return La diff√©rence entre l'estimation et la valeur r√©elle.
diff_estim <- function(size, estimator, real) {
  x_ <- gen_x(size)
  y_ <- gen_y(x_)
  estimation <- estimator(x_, y_)

  abs(estimation - real)
}

#' Calcule la moyenne de plusieurs diff√©rences d'estimations entre a et a0.
#' @param size Taille des √©chantillons √† g√©n√©rer.
#' @return La moyenne des diff√©rences.
moyenne_diff_a <- function(size) {
  mean(replicate(100, diff_estim(size, a_estim, a0)))
}

#' Calcule la moyenne de plusieurs diff√©rences d'estimations entre b et b0.
#' @param size Taille des √©chantillons √† g√©n√©rer.
#' @return La moyenne des diff√©rences.
moyenne_diff_b <- function(size) {
  mean(replicate(100, diff_estim(size, b_estim, b0)))
}

sizes <- seq(min_n, 30 * min_n, by = 50)
erreurs_a_hat <- sapply(sizes, moyenne_diff_a)
erreurs_b_hat <- sapply(sizes, moyenne_diff_b)
```

Pour l'affichage des estimations, on se porte sur un intervalle
$[`r min_n`, 30 \times `r min_n`] = [`r min_n`, `r 30 * min_n`]$. 

```{r, eval=TRUE}
plot(
  sizes,
  erreurs_a_hat,
  type = "l",
  col = "red",
  xlim = c(min(sizes), max(sizes)),
  ylim = c(0, max(erreurs_a_hat)),
  xlab = "Taille de l'√©chantillon",
  ylab = "Erreur moyenne de l'estimation",
  main = "√âtude de la convergence en probabilit√© des estimateurs de a et b"
)
lines(
  sizes,
  erreurs_b_hat,
  col = "blue"
)

legend("topright",
  legend = c("Estimateur de a", "Estimateur de b"),
  col = c("red", "blue"),
  lwd = 1
)
```

Les deux estimateurs semblent tous deux se rapprocher d'une valeur suffisamment
proche de $0$, on peut donc en d√©duire la convergence de l'erreur des estimations
vers $0$, ce qui signifie que les estimations convergent vers la valeur r√©elle
avec du param√®tre pour $n$ grand.

#### Diagrammmes en bo√Æte

Une autre approche pour calculer la convergence est de tracer des diagrammes en bo√Æte pour plusieurs jeux de donn√©es de diff√©rentes tailles. En lieu et place de la moyenne, l'indicateur central est la m√©diane, et les graphiques sont plus complets, en particulier avec l'√©cart inter-quartile qui donne une id√©e de la dispersion des estimations.

Comme pr√©c√©demment, on commence par g√©n√©rer les fonctions qui vont g√©n√©rer les donn√©es et tracer le graphique :

```{r}
#' Trace un diagramme en bo√Æte pour un estimateur donn√©.
#' @param estimator Fonction calculant l'estimation √† partir des donn√©es.
#' @param name Le nom de l'estimateur, utilis√© dans la l√©gende du diagramme.
#' @param sizes Les tailles de jeux de donn√©es.
#' @param real Valeur r√©elle du param√®tre estim√©.
trace_boxplots_estimateur <- function(estimator, name, sizes, real) {
  n <- 100

  # Matrice contenant les r√©sultats des simulations (une simulation par colonne)
  results <- matrix(ncol = length(sizes), nrow = max(sizes))
  colnames(results) <- sizes

  # Simulation pour chaque taille d'√©chantillon
  for (i in seq_along(sizes)) {
    results[, i] <- replicate(n, {
      x_ <- gen_x(sizes[i])
      y_ <- gen_y(x_)
      estimator(x_, y_)
    })
  }

  boxplot(results,
    ylab = name,
    xlab = "Taille d'√©chantillon de x et y",
    main = paste("Convergence de", name, "\npour", n, "estimations")
  )

  # Affichage d'une ligne de r√©f√©rence
  abline(
    h = real,
    col = "red",
    lty = 2,
    lwd = 2
  )

  legend("topright",
    legend = "Valeur r√©elle",
    col = "red",
    lty = 2,
    lwd = 2
  )
}
```

On g√©n√®re c√¥te √† c√¥te les diagrammes en bo√Ætes des deux estimateurs, en
d√©finissant √† l'avance les tailles de jeux de donn√©es :

```{r}
par(mfrow = c(1, 2))
sizes <- c(200, 500, 1000, 9000)
trace_boxplots_estimateur(a_estim, "^a", sizes, a0)
trace_boxplots_estimateur(b_estim, "^b", sizes, b0)
```

Pour chaque estimateur, non seulement la m√©diane se rapproche de la valeur r√©elle du param√®tre, mais l'√©cart-interquartile diminue drastiquement pour $n$ grand, preuve de la convergence des estimateurs.


### Question 10

Notre prochaine √©tape de l'√©tude des estimateurs consiste √† calculer un intervalle de confiance pour chacun d'eux. La loi de chaque estimateur est connue, mais nous nous concentrerons ici uniquement sur celle de $\hat a$ :

$$
\hat{a} \sim \mathcal{N}
\left(
a,
\frac{\sigma^2}{n}
\left(1 + \frac{\bar x}{s_x^2} \right)
\right),
\ \text{avec }
s_x^2 = \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2
$$

En centrant-r√©duisant $\hat a$, et en rempla√ßant $\sigma^2$ par son estimateur $\hat \sigma^2$, on obtient l'expression suivante, dont on cherche √† conna√Ætre la loi pour s'assurer qu'il s'agisse bien d'un pivot, afin de l'utiliser dans notre intervalle de confiance :

$$
\frac{\hat a - a}{\sqrt{\frac{\hat \sigma ^2}{n} \left(1 + \frac{\bar x ^2}{s^2_x}\right)}}
$$

Par une suite de calcul, il est possible d'affirmer que cette expression suit une loi de Student √† $n-2$ degr√©s de libert√©. Pour le confirmer, nous allons √©tudier empiriquement son comportement.

Nous commen√ßons par d√©finir une fonction `pivot_a`, qui mod√©lise l'expression √† √©tudier :

```{r}
#' G√©n√®re des r√©alisations du pivot de a sur diff√©rents jeux de donn√©es.
#' @param n Taille des jeux de donn√©es
#' @return Un vecteur contenant l'estimation de a et son pivot
pivot_a <- function(n) {
  # G√©n√©ration des jeux de donn√©es
  x_ <- gen_x(n)
  y_ <- gen_y(x_)

  # Calcul des valeurs interm√©diaires
  a_hat <- a_estim(x_, y_)
  sigma_hat <- sigma_estim(x_, y_)
  x_bar <- mean(x_)

  # R√©sultat
  res <- (a_hat - a0) / sqrt(((sigma_hat^2 / n) * ((1 + x_bar^2) / var(x_))))

  c(
    estimation = a_hat,
    pivot = res
  )
}
```

```{r, echo=FALSE}
n_q10 <- 1000
```

Nous simulons ensuite $150$ r√©alisations de l'expression pour des jeux de donn√©es de taille $`r n_q10`$ :
```{r}
# 10.1
xsn2 <- data.frame(t(replicate(150, pivot_a(n_q10))))
```

En plus de nous renvoyer la r√©alisation de l'expression du pivot, la fonction `pivot_a` nous transmet l'estimation de $a$ qu'elle a utilis√© pour produire le calcul. Il nous est ainsi possible d'observer par exemple les 5 premi√®res estimations :

```{r, echo=FALSE}
#10.2
head(xsn2$estimation, 5)
```

Nous affichons l'histogramme des pivots de a, nous permettant de voir la forme de la fonction de densit√© de la loi suivie par ce pivot. En y superposant la courbe de la fonction de densit√© de student √† $n-2$ degr√©s de libert√© (ici $`r n_q10 - 2`$), on remarque bien que l'expression suit cette loi.

```{r, echo=FALSE}
# 10.3
hist(xsn2$pivot,
  freq = FALSE,
  xlab = "Pivot",
  ylab = "Densit√©",
  main = "Fonction de densit√© empirique\ndu pivot de a"
)
curve(dt(x, df = n_q10 - 2), add = TRUE, col = "red")

legend("topright",
  legend = "Student(n-2)",
  col = "red",
  lwd = 1
)
```

### Question 11

Nos trois pivots seront donc les suivants, pour chaque estimateur :

$$
\frac{\hat a - a}{\sqrt{\frac{\hat \sigma ^2}{n} \left(1 + \frac{\bar x ^2}{s^2_x}\right)}} \sim \mathcal{T}_{n-2} \qquad
\frac{\hat b - b}{\sqrt{\frac{\hat \sigma ^ 2}{ns_x^2}}} \sim \mathcal{T}_{n-2} \qquad
(n-2)\frac{\hat \sigma ^2}{\sigma^2} \sim \chi_{n-2}^2
$$

Pour chaque pivot, nous g√©n√©rons un intervalle de confiance au travers des
fonctions R `gen_IC_a`, `gen_IC_b` et `gen_IC_s`. Au m√™me titre que pour les
estimateurs, ici chaque fonction :

- V√©rifie la validit√© des vecteurs transmis,
- Calcule les variables interm√©diaires n√©cessaires,
- Retourne l'intervalle de confiance.

```{r}
#' V√©rifie que les vecteurs x_ et y_ transmis aux IC sont valides.
#' @param x_ Vecteur de la variable explicative.
#' @param y_ Vecteur de la variable √† expliquer.
#' @param confiance Degr√© de confiance
#' @return Rien, mais g√©n√®re une erreur si les vecteurs ne sont pas valides.
assert_ic_valid <- function(x_, y_, confiance) {
  stopifnot(length(x_) == length(y_))
  stopifnot(length(x_) > 2)
  stopifnot(confiance > 0 && confiance < 1)
}

#' Retourne un vecteur de taille 2 avec x et -x.
#' @param x un scalaire.
#' @return [-x, x].
pm <- function(x) {
  x * c(-1, 1)
}

#' G√©n√®re une r√©alisation d'un intervalle de confiance bilat√©ral de √¢.
#' @param x  Vecteur de la variable explicative.
#' @param y_ Vecteur de la variable √† expliquer.
#' @param confiance Le niveau de confiance.
#' @return Un vecteur de taille 2 contenant la borne inf√©rieure et sup√©rieure
#' l'intervalle.
gen_IC_a <- function(x_, y_, confiance = 0.95) {
  assert_ic_valid(x_, y_, confiance)

  n <- length(x_)
  alpha <- 1 - confiance
  x_bar <- mean(x_)
  s_x2 <- (1 / n) * sum((x_ - x_bar)^2)

  t_ <- qt(1 - (alpha / 2), df = (n - 2))
  a_hat <- a_estim(x_, y_)
  s_hat <- sigma_estim(x_, y_)

  a_hat + pm(t_ * sqrt((s_hat / n) * (1 + (x_bar^2 / s_x2))))
}

#' G√©n√®re une r√©alisation d'un intervalle de confiance bilat√©ral de b^.
#' @param x  Vecteur de la variable explicative.
#' @param y_ Vecteur de la variable √† expliquer.
#' @param confiance Le niveau de confiance.
#' @return Un vecteur de taille 2 contenant la borne inf√©rieure et sup√©rieure
#' l'intervalle.
gen_IC_b <- function(x_, y_, confiance = 0.95) {
  assert_ic_valid(x_, y_, confiance)

  n <- length(x_)
  alpha <- 1 - confiance
  x_bar <- mean(x_)
  s_x2 <- (1 / n) * sum((x_ - x_bar)^2)

  t_ <- qt(1 - alpha / 2, df = n - 2)
  b_hat <- b_estim(x_, y_)
  s_hat <- sigma_estim(x_, y_)

  b_hat + pm(t_ * sqrt(s_hat / (n * s_x2)))
}

#' G√©n√®re une r√©alisation d'un intervalle de confiance bilat√©ral de c^.
#' @param x  Vecteur de la variable explicative.
#' @param y_ Vecteur de la variable √† expliquer.
#' @param confiance  Le niveau de confiance.
#' @return Un vecteur de taille 2 contenant la borne inf√©rieure et sup√©rieure
#' l'intervalle.
gen_IC_s <- function(x_, y_, confiance = 0.95) {
  assert_ic_valid(x_, y_, confiance)

  n <- length(x_)
  alpha <- 1 - confiance
  s_hat <- sigma_estim(x_, y_)
  chi2_ <- qchisq(c(1 - alpha / 2, alpha / 2), df = n - 2)

  (n - 2) * s_hat / chi2_
}
```

### Question 12

Nos fonctions maintenant impl√©ment√©es, il est temps de calculer un ensemble
d'intervalles de confiance pour chaque estimateur avant de les √©tudier √† la
prochaine question.

```{r, echo=FALSE}
n_q12 <- 1000
```

On commence par poser la taille des jeux de donn√©es sur lesquels sont calcul√©s
les intervalles de confiance √† $`r n_q12`$. Pour chaque estimateur, on g√©n√®re
par ailleurs $100$ intervalles.

```{r}
ic_a_100 <- replicate(100, {
  x_ <- gen_x(n_q12)
  y_ <- gen_y(x_)

  gen_IC_a(x_, y_)
})

ic_b_100 <- replicate(100, {
  x_ <- gen_x(n_q12)
  y_ <- gen_y(x_)

  gen_IC_b(x_, y_)
})

ic_s_100 <- replicate(100, {
  x_ <- gen_x(n_q12)
  y_ <- gen_y(x_)

  gen_IC_s(x_, y_)
})
```

Voici les quelques premiers intervalles ainsi g√©n√©r√©s pour chaque estimateur :

```{r echo=FALSE}
ic_frame <- data.frame(
  alpha = t(ic_a_100),
  beta = t(ic_b_100),
  sigma = t(ic_s_100)
)

colnames(ic_frame) <- c("[ùõº‚ÇÅ", "ùõº‚ÇÇ]", "[ùõΩ‚ÇÅ", "ùõΩ‚ÇÇ]", "[ùúé‚ÇÅ", "ùúé‚ÇÇ]")
head(ic_frame, 5)
```

### Question 13
Par simple lecture des intervalles, il n'est pas possible de v√©rifier qu'elles
respectent le degr√© de confiance impos√© lors de leur g√©n√©ration. Pour visualiser
nos intervalles de confiance, le graphique suivant peut √™tre utilis√© :

```{r, echo=FALSE}
#' Dessine les intervalles de confiance
#'
#' @param ICs Matrice des intervalles de confiance
#' @param mu Param√®tre r√©el estim√© par les ICs
#' @param plot Dessine les ICs ou pas
plot_ICs <- function(ICs, mu, plot = TRUE, xlim, main) {
  nic <- ncol(ICs)
  hit <- ICs[1, ] < mu & ICs[2, ] > mu

  if (plot) {
    plot.new()
    if (missing(xlim)) xlim <- mu + c(-1, 1) * max(abs(ICs - mu))
    plot.window(xlim = xlim, ylim = c(0, nic - 1))
    axis(side = 1)
    segments(ICs[1, ], 1:nic, ICs[2, ], 1:nic, lwd = 2, col = 2 + hit)
    lines(c(mu, mu), c(0, nic), type = "l", lty = 2)
    if (!missing(main)) title(main = main)
  }
  # On renvoie le nombre d'intervalles couvrants sans en faire echo
  invisible(list(hit = sum(hit), miss = nic - sum(hit)))
}

par(mfrow = c(1, 3))

plot_ICs(ic_a_100, a0, main = "Intervalles de confiance de a")
plot_ICs(ic_b_100, b0, main = "Intervalles de confiance de b")
plot_ICs(ic_s_100, s0, main = "Intervalles de confiance de ùúé")
```

Sur ce graphique, l'enti√®ret√© des intervalles de confiance apparait color√©, en
vert si le param√®tre estim√© est bien dans l'intervalle de confiance, et en rouge
sinon. La ligne en pointill√© nous guide pour visualiser o√π se trouve le
param√®tre.

Visuellement, on observe bien que ~5% des intervalles n'incluent pas les valeurs
r√©elles de la variable qu'elles doivent encadrer, et cela pour $a$, $b$, et
$\sigma^2$.

Nous avons aussi mis en place une fonction (inspir√©e du TP4) qui permet de
calculer le taux de recouvrement des diff√©rents intervalles. Cette m√©thode
apporte une approche num√©rique pour v√©rifier √† nouveau le degr√© de confiance :

```{r}
tauxRecouvrement <- function(estimateur, ICs) {
  couverts <- estimateur >= ICs[1, ] & estimateur <= ICs[2, ]
  mean(couverts)
}
```

```{r echo=FALSE}
c(
  "Recouvrement a" = tauxRecouvrement(a0, ic_a_100),
  "Recoubrement b" = tauxRecouvrement(b0, ic_b_100),
  "Recouvrement ùúé" = tauxRecouvrement(s0, ic_s_100)
)
```

## 3. Homosc√©dasticit√©, ind√©pendance et normalit√© des r√©sidus

Dans cette partie, nous nous int√©ressons aux hypoth√®ses $H$ √©nonc√©es pour les r√©sidus corrig√©s. Pour rappel, la formule est la suivante :

$$
\tilde{\varepsilon}_i = \frac{\hat{\varepsilon}_i}{\sqrt{1 - h_i}}, \quad \text{avec } h_i = \frac{1}{n} + \frac{(x_i - \bar{x})^2}{\sum_{j=1}^{n}(x_j - \bar{x})^2}, \quad i = 1, \ldots, n.
$$

Nous testerons les formules et les hypoth√®ses sur le quartet d'Anscombe (int√©gr√© √† R par d√©faut). Ces quatres jeux de donn√©es sont particuli√®rement int√©ressants, puisqu'ils partagent tous des propri√©t√©s statistiques relativement identique (moyennes, variances...), mais ont des distribution de donn√©es diff√©rents.

### Question 14

Pour comprendre dans un premier temps la distribution du quartet, il est
n√©cessaire de les repr√©senter graphiquement. 

Pour chaque graphique, nous affichons le nuage de point, suivi de la droite
de r√©gression lin√©aire calcul√©e par R. Les r√©gressions seront √©tudi√©es plus en
d√©tails dans la question suivante.

```{r, echo=FALSE, fig.height=8, fig.cap="Repr√©sentation du Quartet d'Anscombe"}
xmax <- max(anscombe$x1, anscombe$x2, anscombe$x3, anscombe$x4)
ymax <- max(anscombe$y1, anscombe$y2, anscombe$y3, anscombe$y4)

#' Affiche un jeu de donn√©es d'Anscombe
#' @param x_dataset Le jeu de donn√©es des x
#' @param y_dataset Le jeu de donn√©es des y
#' @param i Le num√©ro du jeu de donn√©es
plot_anscombe <- function(x_dataset, y_dataset, i) {
  stopifnot(0 < i, i <= 4)

  plot(
    x_dataset,
    y_dataset,
    xlim = c(0, xmax),
    ylim = c(0, ymax),
    xlab = "x",
    ylab = "y",
    main = paste("Anscombe #", i, sep = "")
  )

  abline(lm(y_dataset ~ x_dataset))
}

par(mfrow = c(2, 2))
plot_anscombe(anscombe$x1, anscombe$y1, 1)
plot_anscombe(anscombe$x2, anscombe$y2, 2)
plot_anscombe(anscombe$x3, anscombe$y3, 3)
plot_anscombe(anscombe$x4, anscombe$y4, 4)
```

### Question 15

La fonction standard `lm` nous permet d'effectuer les r√©gressions lin√©aires sur
les 4 jeux de donn√©es :

```{r}
reg1 <- lm(anscombe$y1 ~ anscombe$x1)
reg2 <- lm(anscombe$y2 ~ anscombe$x2)
reg3 <- lm(anscombe$y3 ~ anscombe$x3)
reg4 <- lm(anscombe$y4 ~ anscombe$x4)
```

<!-- Nous pouvons ensuite obtenir un r√©sum√© num√©rique gr√¢ce √† la fonction `summary`. -->

Pour √©viter de faire une succession de `summary` complets difficilement
lisibles, nous avons extrait dans un m√™me tableau quelques donn√©es int√©ressantes
√† mettre en avant :

```{r, echo=FALSE}
sreg1 <- summary(reg1)
sreg2 <- summary(reg2)
sreg3 <- summary(reg3)
sreg4 <- summary(reg4)

data.frame(
  reg1 = c(reg1$coefficients, sreg1$adj.r.squared, sreg1$r.squared),
  reg2 = c(reg2$coefficients, sreg2$adj.r.squared, sreg2$r.squared),
  reg3 = c(reg3$coefficients, sreg3$adj.r.squared, sreg3$r.squared),
  reg4 = c(reg4$coefficients, sreg4$adj.r.squared, sreg4$r.squared),
  row.names = c("(Intercept)", "x", "Multiple R-Squared", "Adjusted R-Squared")
)
```

Nous remarquons que les quatre r√©gressions ont des param√®tres de r√©gression dont
les valeurs sont proches. Il en va de m√™me pour les coefficients de
corr√©lation, qui avoisinent les 0.66 en corrig√© comme en non-corrig√©.

Nous pouvons donc en d√©duire que, bien que les statistiques soient similaires,
il ne faut pas en tirer une conclusion h√¢tive, car cela ne signifie pas
n√©cessairement que les donn√©es $(x_i, y_i)$ sont identiques. Cela peut
notamment √™tre illustr√© par la question pr√©c√©dente, o√π les couples de donn√©es
diff√®rent des autres.


### Question 16
Pour analyser les r√©sidus et discuter de la validit√© des hypoth√®ses $H$ des
couples de variable des jeux de donn√©es d'Anscombe, nous nous baserons sur une
√©tude visuelle des graphiques suivants :

- Un diagramme quantile-quantile des r√©sidus corrig√©s, qui nous permettra de
  v√©rifier l'hypoth√®se de normalit√©;
- Un histogramme des r√©sidus corrig√©s, venant appuyer le diagramme pr√©c√©dent sur
  la m√™me hypoth√®se;
- Un nuage de points entre les r√©sidus standardis√©s et de la variable
  explicative, pour v√©rifier l'hypoth√®se d'homosc√©dasticit√© (pour rappel, cette
  hypoth√®se indique l'uniforme variance des r√©sidus corrig√©s).

```{r, echo=TRUE}
#' Calcule les r√©sidus standardis√©s pour un mod√®le de r√©gression lin√©aire
#' simple.
#'
#' @param x_ vecteur des variables explicatives (x)
#' @param reg_ mod√®le de r√©gression (objet retourn√© par lm)
#' @return vecteur des r√©sidus standardis√©s
#'
#' Les r√©sultats de cette fonction sont v√©rifiables avec rstandard.
calcule_residus_corriges <- function(x_, reg_) {
  n_ <- length(x_)
  x_bar_ <- mean(x_)
  Sxx_ <- sum((x_ - x_bar_)^2)

  residuals_ <- reg_$residuals

  hi_ <- (1 / n_) + ((x_ - x_bar_)^2) / Sxx_
  sigma_hat <- sqrt(sum(residuals_^2) / (n_ - 2))

  residuals_ / (sigma_hat * sqrt(1 - hi_))
}

#' G√©n√®re les graphiques des r√©sidus standardis√©s d‚Äôun mod√®le lin√©aire
#'
#' @param x_ vecteur des variables explicatives (x)
#' @param y_ vecteur des variables √† expliquer (y)
#' @return Aucun objet retourn√©. Affiche des graphiques.
fq16 <- function(x_, y_) {
  reg_ <- lm(y_ ~ x_)

  residus_corrige_ <- calcule_residus_corriges(x_, reg_)
  # Retirer les valeurs infinies
  # (R g√®re mal les valeurs trop grandes ou trop petites)
  residus_corrige_[!is.finite(residus_corrige_)] <- NA

  par(mfrow = c(1, 3))
  qqnorm(residus_corrige_, main = "QQ-plot des residus standardises")
  qqline(residus_corrige_, col = "red")

  hist(residus_corrige_,
    freq = FALSE,
    main = "Histogramme des residus \ncorriges",
    xlab = "Residus standardises"
  )
  curve(
    dnorm(x,
      mean = mean(residus_corrige_, na.rm = TRUE),
      sd = sd(residus_corrige_, na.rm = TRUE)
    ),
    add = TRUE,
    col = "red"
  )

  plot(x_, residus_corrige_, main = "Residus corrige en fonction de x")
}
```

```{r, echo=FALSE, fig.cap="Analyse du jeu de donn√©e Anscombe #1", fig.height=3.5}
fq16(anscombe$x1, anscombe$y1)
```

```{r, echo=FALSE, fig.cap="Analyse du jeu de donn√©e Anscombe #2", fig.height=3.5}
fq16(anscombe$x2, anscombe$y2)
```

```{r, echo=FALSE, fig.cap="Analyse du jeu de donn√©e Anscombe #3", fig.height=3.5}
fq16(anscombe$x3, anscombe$y3)
```

```{r, echo=FALSE, fig.cap="Analyse du jeu de donn√©e Anscombe #4", fig.height=3.5}
fq16(anscombe$x4, anscombe$y4)
```

**Analyse des couples** :

- $(x_1, y_1)$: 
    - **QQ-plot** : la distribution des r√©sidus suit √† peu pr√®s la droite de la
      loi normale centr√©e. Une distribution normale des r√©sidus est donc
      plausible.
    - **Histogramme** : on remarque une certaine ressemblance avec une loi
      normale centr√©e, ce qui vient appuyer le diagramme quantile-quantile.
    - **Nuage de point** : on observe que les points sont r√©partis autour de 0,
      sans forme particuli√®re, ce qui confirme l‚Äôhypoth√®se d‚Äôhomosc√©dasticit√©.
- $(x_2, y_2)$: 
    - **QQ-plot** : ce graphique pr√©sente des propri√©t√©s similaires √† celles du
      couple pr√©c√©dent. Toutefois, on peut distinguer une valeur notablement
      √©loign√©e de la droite, ce qui sugg√®re la pr√©sence d‚Äôun point mal expliqu√©
      par le mod√®le.
    - **Histogramme** : le graphique ne suit pas la fonction densit√© de la
      gaussienne, il est donc difficile d‚Äôaffirmer que les r√©sidus suivent une
      loi normale centr√©e et r√©duite.
    - **Nuage de point** : on remarque une forme courb√©e ressemblant √† un polyn√¥me de degr√© deux. Ce qui indique que la relation entre le couple de variable $(x_2, y_2)$, n'est pas lin√©aire et que le mod√®le ne suit pas le mod√®le de r√©gression lin√©raire simple.
- $(x_3, y_3)$:
    - **QQ-plot** : la majorit√© des points sont tr√®s proches des quantiles de la
      loi normale centr√©e r√©duite, √† l‚Äôexception d‚Äôun point aberrant. En effet,
      la valeur de ce point est beaucoup trop √©loign√©e de la droite de
      r√©gression. On exclut donc l‚Äôhypoth√®se que les r√©sidus suivent une loi
      normale centr√©e r√©duite.
    - **Histogramme** : le graphique suit en quelque sorte la courbe de la loi
      normale centr√©e, mais nous ne le prendrons pas en compte √©tant donn√© que
      le QQ-plot n‚Äôest pas conforme.
    - **Nuage de points** : les points se suivent lin√©airement, mais la
      r√©partition des r√©sidus n‚Äôest pas homog√®ne autour de 0 en $x$. L‚Äôhypoth√®se
      d‚Äôhomosc√©dasticit√© n‚Äôest donc pas respect√©e.
- $(x_4, y_4)$:
    - **QQ-plot** : Le diagramme quantile-quantile est parfait, tous les points
      suivent l'allure de la droite normale centr√©e r√©duite.
    - **Histogramme** : cependant, la r√©partition des valeurs sur l‚Äôhistogramme
      est un peu douteuse, car il y a une concentration importante des valeurs
      des r√©sidus sur la borne gauche. Nous pouvons donc rejeter l‚Äôhypoth√®se que
      les r√©sidus suivent une loi normale centr√©e r√©duite.
    - **Nuage de points** : la grande majorit√© des valeurs sont concentr√©es √† la
      valeur huit en abscisse. La r√©partition des r√©sidus reste similaire
      lorsque les valeurs des $x_i$ augmentent. L‚Äôhypoth√®se d‚Äôhomosc√©dasticit√©
      n‚Äôest donc pas valide.
    
Le seul couple qui est le plus apte √† suivre une mod√©lisation de r√©gression
lin√©aire simple est $(x_1, y_1)$. Cette conclusion √©tait instinctivement
pr√©dictible √† la vue des graphiques de la section pr√©c√©dente.


## 4. Jeu de donn√©es r√©elles Real_Data
### 4.1 Quelques √©l√©ments de statistique descriptive

#### Question 17

#### Import des donn√©es

```{r, echo=FALSE}
car_data <- read.csv2("car.csv", sep="\t")
bodyfat_data <- read.table("bodyfat.dat", header=T)
happiness_data <- read.csv("happiness_csv.csv")
```

#### Analyse du fichier `car.csv`

Test de corr√©lation entre les donn√©es discr√®tes, concernant les voitures, afin de d√©terminer leur utilisabilit√©. Les deux bloques de code ci-dessous permetent de transformer les donn√©es non num√©riques en donn√©es num√©riques, afin qu‚Äôelles puissent √™tre trait√©es.

```{r, echo=FALSE}
# sous modele et sous-model
car_data$Sous.mod√®le <- as.integer(factor(car_data$Sous.mod√®le))
car_data$Mod√®le <- as.integer(factor(car_data$Mod√®le))
cor(car_data$Mod√®le, car_data$Sous.mod√®le)
```
Nous remarquons que la corr√©lation entre les donn√©es Model et Sous-model est assez faible. Cette premi√®re indication permet d‚Äôen d√©duire que ce couple n‚Äôest pas pertinent, et nous l'√©cartons donc de nos choix.


```{r, echo=FALSE}
# litre et cylindrique
cor(car_data$Litre, car_data$Cylindr√©e)
reg <- lm(car_data$Cylindr√©e~ car_data$Litre)
plot(car_data$Litre, car_data$Cylindr√©e)
abline(reg)
```
Pour les donn√©es litre et cylindrique, nous constatons une tr√®s forte corr√©lation entre les deux variables. Cependant, lorsque nous tra√ßons le nuage de points, nous remarquons des alignements sur certaines valeurs fixes de l‚Äôaxe des ordonn√©es. Plus pr√©cis√©ment, trois regroupements apparaissent autour de trois constantes $k_i \mid 1 \leq i \leq 3$.
De plus, le nuage de points ne suit pas la tendance de la droite de r√©gression. Nous en d√©duisons que cette paire de variables al√©atoires n‚Äôest pas exploitable, et nous d√©cidons donc de l‚Äô√©carter.

Apr√®s avoir transform√© les variables qualitatives discr√®tes (sous forme de cha√Ænes de caract√®res) en variables num√©riques. Toutefois, ces transformations ne nous ont pas permis d‚Äôobtenir des r√©sultats v√©ritablement exploitables. Cela notament due fait que ces variables ne sont pas des donn√©es discr√®tes ordonn√©es, ce qui est le cas pour l'ensemble des donn√©es discretes qui sont fournis dans le fichier.

Maintenant, il ne nous reste plus qu‚Äô√† v√©rifier la corr√©lation entre les variables continues pr√©sentes dans le jeu de donn√©es.
Mais avant cela, voici deux fonctions que nous allons utiliser pour la suite de cette question. Ces fonctions permettent, de mani√®re simple, de repr√©senter la corr√©lation entre l‚Äôensemble des couples possibles et de renvoyer ceux qui respectent un seuil minimal de corr√©lation sp√©cifi√© en param√®tre (threshold).

```{r, echo=FALSE}
#' Recherche tous les couples de variables dont la corr√©lation 
#'     est sup√©rieure ou √©gale au pourcentage fourni, ou n√©gativement
#'     inf√©rieure ou √©gale.
#' @param data_ Un data.frame contenant les donn√©es √† analyser.
#' @param headers Un vecteur de noms de colonnes (ou d'indices) sur 
#'     lesquelles calculer les corr√©lations.
#' @param threshold Un seuil num√©rique (entre 0 et 1) au-dessus duquel
#'     la corr√©lation est consid√©r√©e comme √©lev√©e.
#' @return Une liste contenant :
#'   - pairs : les indices des paires de variables hautement corr√©l√©es
#'   - cors : la matrice compl√®te des corr√©lations
get_high_correlations <- function (data_, headers, threshold) {
  data <- data_ # Copie de donn√©es
  cors <- cor(data[, headers])
  cors[lower.tri(cors, diag=TRUE)] <- 0
  high_cor_mask <- cors >= threshold | cors <= -threshold
  pairs <- which(high_cor_mask, arr.ind = TRUE)
  list(pairs = pairs, cors = cors)
}

#' Affiche les paires de variables avec leur coefficient de corr√©lation.
#' @param pairs_ Matrice d‚Äôindices 
#' @param cors_ Matrice de corr√©lation
display_high_correlations <- function (pairs_, cors_) {
  for(i in seq_len(nrow(pairs_))) {
    row <- pairs_[i, "row"]
    col <- pairs_[i, "col"]
    cat(
      rownames(cors_)[row], "-", colnames(cors_)[col], ": ", cors_[row, col], "\n"
    )
  }
}
```

```{r, echo=FALSE}
car_cor <- get_high_correlations(
  car_data, 
  c("Prix", "Km", "Litre"), 
  0.1)
  
display_high_correlations(car_cor$pairs, car_cor$cors)
```
Nous voyons ici que la corr√©lation la plus √©lev√©e est d‚Äôenviron 56 %, ce qui, √† premi√®re vue, n‚Äôest pas suffisant pour r√©aliser une mod√©lisation par r√©gression lin√©aire simple.
Nous pouvons alors en conclure que le fichier contenant des donn√©es sur les voitures n‚Äôest pas exploitable, au vu des r√©sultats obtenus.

#### Analyse du fichier `bodyfat.dat`
```
bodyfat_cor <- get_high_correlations(
  bodyfat_data,
  c("Triceps", "Fat", "Midarm", "Thigh"),
  0.7)

display_high_correlations(bodyfat_cor$pairs, bodyfat_cor$cors)
```

En regardant les coefficients de corr√©lation des donn√©es issues de bodyfat.dat, nous remarquons qu‚Äôils sont assez √©lev√©s. Cependant, nous avons √©galement √©cart√© ces donn√©es car nous consid√©rons qu‚Äôelles sont trop peu nombreuses pour une mod√©lisation de r√©gression lin√©aire simple.


#### Analyse du fichier `happiness_csv.csv`

```{r, echo=FALSE}
happiness_cor <- get_high_correlations(
  happiness_data, 
  c("Happiness.Score", "Standard.Error", "Economy..GDP.per.Capita.", "Family", 
    "Health..Life.Expectancy.", "Freedom", "Trust..Government.Corruption.", 
    "Generosity", "Dystopia.Residual"), 
  0.7)
  
display_high_correlations(happiness_cor$pairs, happiness_cor$cors)
```

Finalement, nous avons choisi la paire `Economy (GDP per Capita)` et `Happiness.Score`, qui pr√©sente le coefficient de corr√©lation de Pearson le plus √©lev√©, juste apr√®s le couple `Economy..GDP.per.Capita.` et `Health..Life.Expectancy..`
En tra√ßant les nuages de points correspondants (voir les r√©gressions lin√©aires ci-dessous), nous observons que le second nuage de points a une dispersion plus marqu√©e vers le haut que vers le bas, tandis que, √† l‚Äôinverse, le premier couple suit une tendance plus align√©e avec la droite des moindres carr√©s.

```{r, echo=FALSE}
display_high_correlations(happiness_cor$pairs, happiness_cor$cors)
plot(happiness_data$Economy..GDP.per.Capita., happiness_data$Happiness.Score)
abline(lm(happiness_data$Happiness.Score~happiness_data$Economy..GDP.per.Capita.))
plot(happiness_data$Economy..GDP.per.Capita., happiness_data$Health..Life.Expectancy.)
abline(lm(happiness_data$Health..Life.Expectancy.~happiness_data$Economy..GDP.per.Capita.))
```

## 4.2 Estimation ponctuelle et par IC des param√®tres

### Question 18
```{r, echo=FALSE}
x_real <- happiness_data$Economy..GDP.per.Capita.
y_real <- happiness_data$Happiness.Score

par(mfrow = c(1, 1))
display_model <- function(x_, y_, title_) {
  a_hat <- a_estim(x_, y_)
  cat("Estimation parametre a:", a_hat, "\n")
  b_hat <- b_estim(x_, y_)
  cat("Estimation parametre b:", b_hat, "\n")

  model <- lm(y_ ~ x_) # fournis les meme valeur (10e-3 pres) √† que ceux estimer nous meme
  plot(x_, y_, main = title_)
  abline(a_hat, b_hat, col = "red", lwd = 6, lty = 1)
  abline(model, col = "green", lwd = 2, lty = 5)

  return(model)
}

model <- display_model(x_real, y_real, "Happinness score, en fonction du PIB")

```

Lorsque nous tra√ßons la droite des moindres carr√©s ainsi que celle calcul√©e par nos fonctions d‚Äôestimations, nous remarquons que les deux droites sont align√©es : nos estimations sont donc correctes.
De plus, la r√©partition des donn√©es suit la tendance g√©n√©rale de la courbe, ce qui rend le mod√®le de r√©gression lin√©aire envisageable.

### Question 19
Estimation des intervales de confiances, avec lafonction `confint`.
```{r, echo=FALSE}
Yi_real <- a_estim(x_real, y_real) + b_estim(x_real, y_real) * x_real
hp_m_IC <- confint(model, level = 0.05)
print("Estimation des parametre du modeles par intervalle de confiances")
print(hp_m_IC)
```

Maintenant que nous avons nos intervalles, il s'agit de v√©rifier si nos estimations (obtenues avec les fonctions que nous avons d√©velopp√©es) se trouvent bien √† l'int√©rieur de ces intervalles.

```{r, echo=FALSE}
# verifions si a et b appartient a leur IC respective
a_estime_real <- a_estim(x_real, y_real)
b_estime_real <- b_estim(x_real, y_real)
cat("a = ", a_estime_real, " est dans IC: ", a_estime_real >= hp_m_IC[1,][1] & a_estime_real <= hp_m_IC[1,][2], "\n")
cat("b = ", b_estime_real, " est dans IC: ", b_estime_real >= hp_m_IC[2,][1] & b_estime_real <= hp_m_IC[2,][2], "\n")
```

## 4.3 Qualit√© de l‚Äôajustement

### Question 20
Nous rappelons que le calcul du coefficient de d√©termination se fait de la mani√®re suivante :
$$ R^2 = \frac{S_{\text{reg}}}{S_Y^2} \text{, avec}$$

$$ S_{\text{reg}} = \frac{1}{n} \sum_{i=1}^n (\widehat{Y}_i - \overline{Y})^2 \text{, } S_{\text{res}} = \frac{1}{n} \sum_{i=1}^n (Y_i - \widehat{Y}_i)^2 $$

$$ S_Y^2 = \frac{1}{n} \sum_{i=1}^n (Y_i - \overline{Y})^2 = S_{\text{reg}} + S_{\text{res}} $$

```{r, echo=FALSE}
Yi_real <- a_estim(x_real, y_real) + b_estim(x_real, y_real)*x_real

n_q20 <- length(Yi_real)

Sreg <- (1 / n_q20) * sum((Yi_real - mean(y_real))^2)
Sres <- (1 / n_q20) * sum((y_real - Yi_real)^2)
SY02 <- Sreg + Sres
Rsquare <- Sreg / SY02
print(Rsquare)
```

On remarque alors qu‚Äôenviron 60,99 % de la variance est expliqu√©e par la droite des moindres carr√©s, c‚Äôest-√†-dire qu‚Äôenviron 60,99 % des variations de $y$ sont expliqu√©es par $x$.

### Question 21

V√©rification du calcul de $R^2$ avec:
$$
R^2 = \frac{s_{xy}^2}{s_x^2s_y^2} = (\text{correlation empirique entre } x \text{ et } y)^2
$$

$$
\text{o√π } s_{xy}^2 = \left(\frac{1}{n}\sum_{i=1}^n x_iy_i\right)-\bar{x}\bar{y} \text{, } s_x^2 = \frac{1}{n}\sum_{i=1}^n x_i^2 -\bar{x}^2 \text{ et } s_y^2 = \frac{1}{n}\sum_{i=1}^n y_i^2 -\bar{y}^2
$$

```{r, echo=FALSE}
print(cov(x_real, y_real)^2 / (var(x_real) * var(y_real)))
print(cor(x_real, y_real)^2)
```

Nous voyons bien ici que les trois calculs correspondent au m√™me r√©sultat.

### Question 22
Pour cette question, on pose: $H_0: b = b_0 = 0$, contre $H_1: b = b_1 \neq b_0$ avec $\alpha = 0.05$

Pour des soucis de variable, nous allons nommer $b_{real} = b$ et $b_{0real} = b_0$

Nous avons dans un premier temps calcul√© une r√©alisation de 
$$
\frac{\hat{b} - b}{\sqrt{\frac{\hat{\sigma}^2}{n s_x^2}}}
$$

Nous cherchons alors une r√©gion critique, tel que:
$$
P_{H_0}(\frac{\hat{b} - b}{\sqrt{\frac{\hat{\sigma}^2}{n s_x^2}}} > c) = \alpha \text{, avec } c = t_{n - 2,\,1 - \frac{\alpha}{2}}
$$

```{r, echo=FALSE}
b0_real <- 0
b_real <- b0_real
m <- length(x_real)
T_real <- (b_estime_real - b_real) / sqrt(sigma_estim(x_real, y_real) / (m * var(x_real)))
alpha_start <- 0.05
W <- pm(qt(1 - alpha_start / 2, df = m - 2))

cat("La region critique W est alors de : \nW:={", W[1], "> T >", W[2], "}\n")
cat("Notre T =", T_real, "tombe dans :\nW:={ T >", W[2], "}\n")
```

Le risque de premi√®re esp√®ce nous indique que sous $H_0$, la probabilit√© d‚Äôobserver $T > 1.975$ est de 5%.
Or ici, T est significativement sup√©rieur, nous rejetons alors formellement l‚Äôhypoth√®see $H_0$. Donc le mod√®le de r√©gression lin√©aire simple est justifi√©.

De plus, nous pouvons appuyer ce propos en calculant la p-value :  
$$P_{H_0}(T > 15.66711) = 1 - P_{H_0}(T \le 15.66711) = P_{H_0}(T \le -15.66711)$$

```{r, echo=FALSE}
p_value <- 2 * pt(-15.66711, df = m - 2)
print(p_value)
```

Nous voyons l√† que la p-value est proche de 0, donc sous $H_0$, il serait quasiment impossible d‚Äôobserver une valeur sup√©rieure ou √©gale √† 15.66711, on rejete alors $H_0$.
La p-value vient alors renforcer l‚Äôexistence du coefficient directeur de la r√©gression, et donc la validit√© du mod√®le de r√©gression lin√©aire simple, c'est √† dire le rejet de $H_0$ et la conservation de $H_1$.

### Question 23

**Normalit√©**
```R
test_normalite <- function(x_, y_) {
  e_real <- rstandard(lm(y_ ~ x_))
  qqnorm(e_real, main = "QQ-plot des residus standardises ")
  qqline(e_real, col = "red")
}

test_normalite(x_real, y_real)
```

Nous remarquons ici que la grande majorit√© des points (r√©sidus) suit la tendance de la droite. La distribution des r√©sidus par rapport √† une loi normale est acceptable.

### Question 24

**Homosc√©dasticit√©**
```R
test_homoscedasticite <- function(x_, y_) {
  reg <- lm(y_~x_)
  res <- rstandard(reg)
  
  plot(x_, res,
       main = "Test d'homosc√©dasticit√©",
       xlab = "Variable explicative (PIB)",
       ylab = "R√©sidus standardis√©s",
       pch = 20,
       col = "blue")
  
  abline(h = 0, col = "red", lty = 2)
}

test_homoscedasticite(x_real, y_real)
```
Sur le nuage de points, on observe globalement une r√©partition al√©atoire des valeurs. En tra√ßant la droite $y = 0$, nous constatons une dispersion al√©atoire autour de celle-ci, sans motif ni r√©p√©tition identifiable.
Nous pouvons donc conclure que, visuellement, les r√©sidus corrig√©s semblent ind√©pendants et valident l‚Äôhypoth√®se d‚Äôhomosc√©dasticit√©.

## 4.5 Pr√©vision

### Question 25

#### Intervalle de confiance pour $\mathbb{E}(\hat{Y}_0)$

D'apr√®s les r√©sultats trouv√©s pr√©c√©demment, nous savons que la mod√©lisation par une r√©gression lin√©aire simple semble valide. Nous avons alors la possibilit√© de l'utiliser afin de faire une pr√©diction pour une valeur $\hat{Y_0}$ en fonction de $x_0$.

Afin de trouver l'intervalle de confiance de $≈∂_0$, nous cherchons d'abord une fonction de pivot.

On pose:
$$
\hat{Y}_0 = \hat{a} + \hat{b}x_0
$$

Nous avons:

$$
≈∂_0 \sim \mathcal{N}(E(\hat{Y}_0), Var(\hat{Y}_0))
\iff \frac{\hat{Y}_0 - E(\hat{Y}_0)}{\sqrt{Var(\hat{Y}_0)}} \sim \mathcal{N(0, 1)}\newline
$$

Avec $Var(≈∂_0)$ tel que:

$$
\begin{align*}
Var(≈∂_0) &= Var(\hat{a}) + x_0^2 \cdot Var(\hat{b}) + 2x_0 \cdot Cov(\hat{a}, \hat{b})\newline
&= \frac{\sigma^2}{n} \cdot (1 + \frac{(x_0 - \bar{x})^2}{s^2_x})
\end{align*}
$$

Cependant, $\sigma^2$ est inconnue, nous la rempla√ßons donc dans notre expression par l'estimateur sans biais $\hat{\sigma}^2$, tel que:

$$
\begin{align*}
\hat{\sigma}^2 &= \frac{1}{n-2} \sum_{i=1}^{n} (Y_i - \hat{a} - \hat{b}x_i)^2 \newline
\end{align*}
$$

On note aussi que :

$$
\frac{\hat{\sigma}^2}{\sigma^2}(n-2) \sim \chi_{n-2}^2
$$

Notre fonction pivot $\pi$ a donc pour forme:

$$
\begin{align*}
\pi = \frac{\hat{Y}_0 - E(\hat{Y}_0)}{\hat{\sigma}\sqrt{\frac{1}{n} \cdot (1 + \frac{(x_0 - \bar{x})^2}{s^2_x})}}
\end{align*}
$$

Nous souhaitons retrouver la loi de $\pi$, pour cela, nous essayons de l'exprimer sous la forme:

$$
\frac{U}{\sqrt{\frac{Ch}{d}}} \sim \mathcal{t}_d
$$

o√π $U \sim \mathcal{N}(0, 1)$, et $Ch \sim \chi_d^2$.

On pose:

$$
U = \frac{\hat{Y}_0 - E(\hat{Y}_0)}{\sigma\sqrt{\frac{1}{n}(1 + \frac{(x_0 - \bar{x})^2}{s^2_x})}}
$$

ainsi que , $d = n - 2$ et :

$$
\begin{align*}
Y &= \frac{\hat{\sigma}^2}{\sigma^2}(n-2)\newline
\iff \hat{\sigma} &= \sigma \sqrt{\frac{Ch}{n-2}}
\end{align*}
$$

En rempla√ßant $\hat{\sigma}^2$ par cette nouvelle d√©finition, on obtient bien:

$$
\pi = \frac{1}{\sqrt{\frac{Ch}{n-2}}} \cdot \frac{≈∂_0 - E(≈∂_0)}{\sigma \sqrt{\frac{1}{n} \cdot (1 + \frac{(x_0 - \bar{x})^2}{s^2_x})}} = \frac{U}{\sqrt{\frac{Ch}{d}}} \sim \mathcal{t}_{n-2}
$$

Soit $\alpha$ tel que  $0 \leq \alpha \leq 1$, et 1 - $\alpha$ le niveau de confiance, alors pour trouver notre intervalle de confiance on pose:

$$
P(|\pi| \leq k) = 1 - \alpha
$$

La loi de Student √©tant sym√©trique autour de 0, nous avons $k = \mathcal{t}_{n - 2, 1 - \frac{\alpha}{2}}$. Nous pouvons donc retrouver l'intervalle exacte:

$$
\begin{align*}
P(&|\pi| \leq k) = 1 - \alpha\newline
\iff & |\pi| \leq \mathcal{t}_{n - 2, 1 - \frac{\alpha}{2}}\newline
\iff &IC = [≈∂_0 \pm \mathcal{t}_{n - 2, 1 - \frac{\alpha}{2}} \cdot \hat{\sigma}\sqrt{\frac{1}{n} \cdot (1 + \frac{(x_0 - \bar{x})^2}{s^2_x})}]
\end{align*}
$$

```{r}
intervalle_confiance <- function(model, x0, alpha = 0.05) {
  x_real <- model$model[, 2]
  y_real <- model$model[, 1]
  n_real <- length(x_real)
  x_bar_real <- mean(x_real)
  s_xx_real <- sum((x_real - x_bar_real)^2)
  sigma_hat_real <- summary(model)$sigma
  
  t_crit <- qt(1 - alpha / 2, df = n_real - 2)
  
  y_hat_0 <- predict(model, newdata = data.frame(x_real = x0))
  
  se_conf_factor <- sqrt((1/n_real) + ((x0 - x_bar_real)^2 / s_xx_real))
  marge_erreur_conf <- t_crit * sigma_hat_real * se_conf_factor
  
  ic_inf <- y_hat_0 - marge_erreur_conf
  ic_sup <- y_hat_0 + marge_erreur_conf
  
  cat("Pour x0 =", round(x0, 3), ":\n")
  cat("Valeur pr√©dite Y_hat_0 =", round(as.numeric(y_hat_0), 3), "\n")
  cat("Intervalle de confiance √†", (1 - alpha) * 100, "% pour E(Y0) : [", 
      round(ic_inf, 3), "; ", round(ic_sup, 3), "]\n")
}
```

### Intervalle de pr√©diction pour une nouvelle observation $Y_0$ √† $x_0$

Cet intervalle donne une plage de valeurs plausibles pour une seule nouvelle observation $Y_0$. Il doit prendre en compte non seulement l'incertitude sur la droite de r√©gression, mais aussi la variabilit√© inh√©rente √† une nouvelle observation (le terme d'erreur $\epsilon_0$). Cet intervalle sera donc toujours plus large que l'intervalle de confiance pour la moyenne.



Pour l'intervalle de pr√©diction de $Y_0$, on s'int√©resse √† l'erreur de pr√©diction $Y_0 - \hat{Y}_0$.

On a $\mathbb{E}[Y_0 - \hat{Y}_0] = 0$ et  $\mathrm{Var}(Y_0 - \hat{Y}_0) = \mathrm{Var}(Y_0) + \mathrm{Var}(\hat{Y}_0)$ (car $Y_0$ est une nouvelle observation ind√©pendante des donn√©es ayant servi √† estimer $\hat{Y}_0$).

Avec $Sxx = n\cdot s^2_x$, on peut r√©√©crir $\mathrm{Var}(Y_0 - \hat{Y}_0)$ comme √©tant:
$$
\begin{align*}
&\mathrm{Var}(Y_0 - \hat{Y}_0)\newline
= &\sigma^2 + \sigma^2 \left( \frac{1}{n} + \frac{(x_0 - \bar{x})^2}{S_{xx}} \right)\newline
= &\sigma^2 \left( 1 + \frac{1}{n} + \frac{(x_0 - \bar{x})^2}{S_{xx}} \right)
\end{align*}
$$

La quantit√© pivotale pour l'intervalle de pr√©diction de $Y_0$ est :
$$ T_{pred} = \frac{Y_0 - \hat{Y}_0}{\hat{\sigma} \sqrt{1 + \frac{1}{n} + \frac{(x_0 - \bar{x})^2}{S_{xx}}}} \sim t_{n-2} $$
L'intervalle de pr√©diction √† $1-\alpha$ pour $Y_0$ est :
$$ \hat{Y}_0 \pm t_{n-2, 1-\alpha/2} \cdot \hat{\sigma} \sqrt{1 + \frac{1}{n} + \frac{(x_0 - \bar{x})^2}{S_{xx}}} $$

```{r}

intervalle_prediction <- function(model, x0, alpha = 0.05) {
  x_real <- model$model[, 2]
  y_real <- model$model[, 1]
  n_real <- length(x_real)
  x_bar_real <- mean(x_real)
  s_xx_real <- sum((x_real - x_bar_real)^2)
  sigma_hat_real <- summary(model)$sigma
  
  t_crit <- qt(1 - alpha / 2, df = n_real - 2)
  
  y_hat_0 <- predict(model, newdata = data.frame(x_real = x0))
  
  se_pred_factor <- sqrt(1 + (1/n_real) + ((x0 - x_bar_real)^2 / s_xx_real))
  marge_erreur_pred <- t_crit * sigma_hat_real * se_pred_factor
  
  ip_inf <- y_hat_0 - marge_erreur_pred
  ip_sup <- y_hat_0 + marge_erreur_pred
  
  cat("Pour x0 =", round(x0, 3), ":\n")
  cat("Valeur pr√©dite Y_hat_0 =", round(as.numeric(y_hat_0), 3), "\n")
  cat("Intervalle de pr√©diction √†", (1 - alpha) * 100, "% pour Y0 : [", 
      round(ip_inf, 3), "; ", round(ip_sup, 3), "]\n")
}

```

On a d√©j√† le mod√®le `model <- display_model(x_real, y_real, "Happinness score, en fonction du PIB")`.
Nous allons choisir deux nouvelles valeurs pour $x_0$. Par exemple, une valeur proche de la moyenne des $x_{\text{real}}$ et une valeur un peu plus √©loign√©e.

```{r}
calcul_intervalles <- function(model, x0_valeurs, alpha = 0.05) {
  cat("Calcul des intervalles pour alpha =", alpha, "(niveau", (1-alpha)*100, "%)\n")
  
  x_real <- model$model[, 2]
  n_real <- length(x_real)
  t_crit_pred <- qt(1 - alpha / 2, df = n_real - 2)
  
  cat("t critique (df=", n_real-2, "): ", round(t_crit_pred, 4), "\n\n", sep="")
  
  for (x0_current in x0_valeurs) {
    intervalle_confiance(model, x0_current, alpha)
    intervalle_prediction(model, x0_current, alpha)
    cat("\n")
  }
}
```
```{r}
model <- lm(y_real ~ x_real)
x0_valeurs <- c(1.0, 1.5)
calcul_intervalles(model, x0_valeurs)
```
### R√©sultats pour les valeurs de pr√©diction

#### Pour x‚ÇÄ = 1.0

| Type d'intervalle | Valeur pr√©dite | Borne inf√©rieure | Borne sup√©rieure |
|-------------------|----------------|------------------|------------------|
| **Confiance (95%)** pour E(Y‚ÇÄ) | 5.717 | 5.596 | 5.838 |
| **Pr√©diction (95%)** pour Y‚ÇÄ | 5.717 | 4.295 | 7.139 |

#### Pour x‚ÇÄ = 1.5

| Type d'intervalle | Valeur pr√©dite | Borne inf√©rieure | Borne sup√©rieure | 
|-------------------|----------------|------------------|------------------|
| **Confiance (95%)** pour E(Y‚ÇÄ) | 6.826 | 6.611 | 7.041 |
| **Pr√©diction (95%)** pour Y‚ÇÄ | 6.826 | 5.393 | 8.260 |

Pour en tra√ßant le point sur le graphique, il est possible de distinguer ce celui-ci ce fond bien parmis les autres.

## 4.6 Conclusion

### Question 26

Nous pouvons donc en conclure que la mod√©lisation du PIB et du Happiness score en tant que variable explicante et variable expliqu√©e est pertinante. L'application de la regression lin√©raire nous permets de pr√©dire des donn√©es avec de intervalles de confiance et de pr√©diction pr√©cis.
